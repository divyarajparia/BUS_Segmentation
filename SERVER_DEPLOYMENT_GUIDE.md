# Complete Server Deployment Guide
## Privacy-Preserving Style Transfer + Training Pipeline

This guide walks through the complete process from scratch on a server: generating styled data, training, and evaluation.

## ğŸ“‹ Prerequisites

- Server with GPU access
- Conda/Python environment
- Access to BUSI and BUS-UCLM datasets on server

## ğŸš€ Step-by-Step Server Deployment

### Step 1: Clone Repository and Setup Environment

```bash
# Clone your repository (without datasets - they're in gitignore)
git clone https://github.com/your_username/your_repo.git
cd your_repo

# Create conda environment
conda create -n bus_segmentation python=3.8 -y
conda activate bus_segmentation

# Install requirements for privacy-preserving style transfer
pip install -r requirements_privacy_preserving.txt

# Install requirements for training (if you have a separate requirements file)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt  # Your main requirements file
```

### Step 2: Upload Datasets to Server

```bash
# Upload BUSI dataset to server
scp -r /local/path/to/BUSI/ user@server:~/BUS_Segmentation/dataset/BioMedicalDataset/

# Upload BUS-UCLM dataset to server  
scp -r /local/path/to/BUS-UCLM/ user@server:~/BUS_Segmentation/dataset/BioMedicalDataset/

# Verify dataset structure
ls dataset/BioMedicalDataset/BUSI/
ls dataset/BioMedicalDataset/BUS-UCLM/
```

Expected structure:
```
dataset/BioMedicalDataset/
â”œâ”€â”€ BUSI/
â”‚   â”œâ”€â”€ train_frame.csv
â”‚   â”œâ”€â”€ test_frame.csv
â”‚   â”œâ”€â”€ val_frame.csv
â”‚   â”œâ”€â”€ benign/
â”‚   â””â”€â”€ malignant/
â””â”€â”€ BUS-UCLM/
    â”œâ”€â”€ train_frame.csv
    â”œâ”€â”€ test_frame.csv
    â”œâ”€â”€ benign/
    â””â”€â”€ malignant/
```

### Step 3: Generate Privacy-Preserving Styled Dataset

```bash
# Run the complete privacy-preserving style transfer pipeline
python run_full_privacy_preserving_pipeline.py
```

This will:
- âœ… Extract BUSI style statistics (485 images)
- âœ… Generate 184 BUSI-styled BUS-UCLM images using gradient_based method
- âœ… Create combined training CSV (669 total samples)
- âœ… Output: `dataset/BioMedicalDataset/BUS-UCLM-Privacy-Styled/`

### Step 4: Train MADGNet on Combined Dataset

```bash
# Train MADGNet using original BUSI + privacy-styled BUS-UCLM
python train_madgnet_with_privacy_styled_data.py \
  --combined_csv dataset/BioMedicalDataset/combined_privacy_preserving_train.csv \
  --test_csv dataset/BioMedicalDataset/BUSI/test_frame.csv \
  --epochs 100 \
  --batch_size 8 \
  --lr 0.001 \
  --output_dir privacy_preserving_results/
```

### Step 5: Evaluate on BUSI Test Set

```bash
# Evaluate trained model on BUSI test set
python evaluate_privacy_preserving_model.py \
  --model_path privacy_preserving_results/best_model.pth \
  --test_csv dataset/BioMedicalDataset/BUSI/test_frame.csv \
  --test_dataset_path dataset/BioMedicalDataset/BUSI \
  --output_dir privacy_preserving_results/evaluation/
```

## ğŸ“Š Expected Timeline

| Step | Estimated Time | Resources |
|------|---------------|-----------|
| Environment Setup | 10-15 minutes | CPU |
| Dataset Upload | 20-30 minutes | Network |
| Style Transfer Generation | 2-5 minutes | CPU |
| MADGNet Training | 2-4 hours | GPU |
| Evaluation | 5-10 minutes | GPU |

## ğŸ¯ Expected Results

Based on CCST paper findings:
- **Dice Score**: +9.16% improvement over BUSI-only training
- **IoU**: +9.46% improvement
- **Hausdorff Distance**: -17.28% improvement

## ğŸ“ˆ Resource Requirements

### Minimum:
- **RAM**: 16GB
- **GPU**: 8GB VRAM (RTX 3070 equivalent)
- **Storage**: 20GB free space

### Recommended:
- **RAM**: 32GB+
- **GPU**: 24GB VRAM (RTX 4090/A100)
- **Storage**: 50GB+ free space

## ğŸ”§ Troubleshooting

### Common Issues:

1. **CUDA Out of Memory**:
   ```bash
   # Reduce batch size
   --batch_size 4
   ```

2. **Dataset Path Issues**:
   ```bash
   # Verify paths
   python -c "import pandas as pd; print(pd.read_csv('dataset/BioMedicalDataset/BUSI/train_frame.csv').head())"
   ```

3. **Style Transfer Fails**:
   ```bash
   # Test single image first
   python test_privacy_preserving_methods.py
   ```

## ğŸ‰ Success Indicators

You'll know it's working when you see:

1. **Style Transfer**: `âœ… Generated 184 styled images`
2. **Training**: Dice loss decreasing over epochs
3. **Evaluation**: Metrics improvement over baseline

## ğŸ“ Final Output Structure

After completion:
```
BUS_Segmentation/
â”œâ”€â”€ dataset/BioMedicalDataset/
â”‚   â”œâ”€â”€ BUSI/                           # Original BUSI
â”‚   â”œâ”€â”€ BUS-UCLM/                       # Original BUS-UCLM  
â”‚   â”œâ”€â”€ BUS-UCLM-Privacy-Styled/        # Generated styled data
â”‚   â””â”€â”€ combined_privacy_preserving_train.csv
â”œâ”€â”€ privacy_preserving_results/
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ training_logs.txt
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ dice_scores.csv
â”‚       â”œâ”€â”€ iou_scores.csv
â”‚       â””â”€â”€ predictions/
â””â”€â”€ privacy_style_stats/
    â””â”€â”€ busi_privacy_stats.json
```

## ğŸ” Privacy Benefits Achieved

âœ… **No raw BUSI images shared between institutions**  
âœ… **Only statistical information exchanged**  
âœ… **Federated learning compatible**  
âœ… **GDPR/HIPAA compliant approach**  

This approach simulates a real federated learning scenario where Institution A (BUSI) shares only style statistics, and Institution B (BUS-UCLM) generates locally-styled data for improved training. 